import open3d as o3d
import numpy as np
import cv2
import os
from pathlib import Path
from cv2.ximgproc import guidedFilter  
from scipy.ndimage import generic_filter
from concurrent.futures import ThreadPoolExecutor, as_completed

# === [1] è·¯å¾‘è¨­å®šï¼ˆæ”¹ç‚ºéè¿´è™•ç† data/ ä¸‹æ‰€æœ‰å ´æ™¯ï¼‰ ===
base_dir = Path(__file__).parent
data_dir = base_dir / "elan_dataset"  # <- ä½ è¦çš„æ ¹ç›®éŒ„åç¨±
output_root = base_dir / "output"
os.makedirs(output_root, exist_ok=True)

max_depth = 80.0

# === [2] ç›¸æ©Ÿå…§åƒçŸ©é™£ K ===
K = np.array([
    [1418.667, 0.0, 640.0],
    [0.0, 1418.667, 360.0],
    [0.0, 0.0, 1.0]
])

# === [3] LiDAR to Camera å¤–åƒçŸ©é™£ ===
T_lidar_to_cam = np.array([
    [ 0.037, -0.999,  0.009,  0.0],
    [-0.094, -0.012, -0.996, -0.3],
    [ 0.995,  0.036, -0.094, -0.43],
    [ 0.0,    0.0,    0.0,    1.0]
])


def load_points(pcd_path: Path) -> np.ndarray:
    """è®€å–é»é›²ï¼Œæ”¯æ´ .pcd èˆ‡ .npyï¼ˆå½¢ç‹€ Nx3ï¼‰ã€‚"""
    if pcd_path.suffix.lower() == ".pcd":
        pcd = o3d.io.read_point_cloud(str(pcd_path))
        pts = np.asarray(pcd.points)
        return pts
    elif pcd_path.suffix.lower() == ".npy":
        arr = np.load(str(pcd_path))
        if arr.ndim == 2 and arr.shape[1] >= 3:
            return arr[:, :3]
        raise ValueError(f"npy å½¢ç‹€ä¸æ­£ç¢º: {pcd_path}ï¼ŒæœŸæœ› Nx3")
    else:
        raise ValueError(f"ä¸æ”¯æ´çš„é»é›²æ ¼å¼: {pcd_path}")


def fast_fill_depth(depth: np.ndarray, iterations: int = 3) -> np.ndarray:
    filled = depth.copy()
    for _ in range(iterations):
        zero_mask = (filled == 0)
        nonzero = (filled != 0).astype(np.float32)
        kernel = np.ones((3, 3), np.float32)
        sum_ = cv2.filter2D(filled, -1, kernel)
        count = cv2.filter2D(nonzero, -1, kernel)
        avg = np.divide(sum_, count, out=np.zeros_like(sum_), where=(count > 0))
        filled[zero_mask] = avg[zero_mask]
    return filled


def process_pair(image_path: Path, pcd_path: Path, out_dir: Path) -> None:
    img_bgr = cv2.imread(str(image_path))
    if img_bgr is None:
        print(f"è®€ä¸åˆ°åœ–ç‰‡: {image_path}")
        return
    H, W = img_bgr.shape[:2]

    # è®€å–é»é›²
    try:
        points = load_points(pcd_path)
    except Exception as e:
        print(f"è®€é»é›²å¤±æ•— {pcd_path}: {e}")
        return

    # æŠ•å½±
    points_hom = np.hstack([points[:, :3], np.ones((points.shape[0], 1))])
    cam_points = (T_lidar_to_cam @ points_hom.T).T
    cam_points = cam_points[cam_points[:, 2] > 0]
    if cam_points.size == 0:
        print(f"ç„¡æœ‰æ•ˆå‰æ–¹é»: {pcd_path}")
        return
    z = cam_points[:, 2]
    x, y = cam_points[:, 0], cam_points[:, 1]
    u = (K[0, 0] * x / z + K[0, 2]).astype(np.int32)
    v = (K[1, 1] * y / z + K[1, 2]).astype(np.int32)

    # å»ºç«‹ depth map + æœ€è¿‘é»ä¿ç•™
    depth_map = np.zeros((H, W), dtype=np.float32)
    valid = (u >= 0) & (u < W) & (v >= 0) & (v < H)
    for i in range(len(u)):
        if valid[i]:
            px, py = u[i], v[i]
            if depth_map[py, px] == 0 or z[i] < depth_map[py, px]:
                depth_map[py, px] = z[i]

    # è£œæ´ï¼ˆåŠ é€Ÿç‰ˆï¼‰ä¸¦åŠ å¼·ä¸‹åŠéƒ¨
    depth_filled = fast_fill_depth(depth_map, iterations=3)
    depth_filled[H // 2 :, :] = fast_fill_depth(depth_filled[H // 2 :, :], iterations=100)

    # è¦–è¦ºåŒ–èˆ‡è¼¸å‡º
    out_dir.mkdir(parents=True, exist_ok=True)
    stem = image_path.stem

    # å„²å­˜ dense depth npy
    depth_npy_path = out_dir / f"{stem}.npy"
    np.save(str(depth_npy_path), depth_filled)

    # å„²å­˜å½©è‰²åœ–
    depth_vis = np.clip(depth_filled, 0, max_depth)
    depth_vis_norm = (depth_vis / max_depth * 255).astype(np.uint8)
    depth_colored = cv2.applyColorMap(depth_vis_norm, cv2.COLORMAP_INFERNO)
    out_png_path = out_dir / f"{stem}.png"
    cv2.imwrite(str(out_png_path), depth_colored)

    print(f"Done: {image_path} -> {out_png_path}")


# === [Main] éè¿´å°‹æ‰¾ data/ ä¸‹çš„æ‰€æœ‰å½±åƒï¼Œé…å°åŒåé»é›² ===
# é æœŸç›®éŒ„çµæ§‹ï¼š
#   data/<scene>/image/XXXXX.jpg
#   data/<scene>/VLS128_pcdnpy/XXXXX.pcd  æˆ–  XXXXX.npy
# è‹¥çµæ§‹ä¸åŒï¼Œå¯è‡ªè¡Œèª¿æ•´ä¸‹é¢çš„é…å°é‚è¼¯ã€‚

image_exts = {".jpg", ".jpeg", ".png"}

if not data_dir.exists():
    raise FileNotFoundError(f"æ‰¾ä¸åˆ°è³‡æ–™å¤¾: {data_dir}")

def _iter_jobs():
    for img_path in data_dir.rglob("*"):
        if img_path.suffix.lower() not in image_exts:
            continue
        try:
            # æœŸå¾… image åœ¨ scene_root/image
            if img_path.parent.name == "image":
                scene_root = img_path.parent.parent
            else:
                # é€€ä¸€æ­¥ï¼šå‡è¨­å½±åƒæ‰€åœ¨ç›®éŒ„å°±æ˜¯ scene_root
                scene_root = img_path.parent
            stem = img_path.stem
            pcd_candidate_pcd = scene_root / "VLS128_pcdnpy" / f"{stem}.pcd"
            pcd_candidate_npy = scene_root / "VLS128_pcdnpy" / f"{stem}.npy"

            if pcd_candidate_pcd.exists():
                pcd_path = pcd_candidate_pcd
            elif pcd_candidate_npy.exists():
                pcd_path = pcd_candidate_npy
            else:
                print(f"è·³éï¼Œæ‰¾ä¸åˆ°åŒåé»é›²: {img_path}")
                continue

            # è¼¸å‡ºæ”¾åœ¨ output/ ä¸‹ï¼Œä¿ç•™ç›¸å°æ–¼ data/ çš„å­è·¯å¾‘
            rel_parent = img_path.parent.relative_to(data_dir)
            # å°‡ç›®éŒ„åç¨± 'image' æ”¹ç‚º 'depth_output'
            if rel_parent.parts[-1] == "image":
                rel_parent = Path(*rel_parent.parts[:-1], "depth_output")
            out_dir = output_root / rel_parent

            yield (img_path, pcd_path, out_dir)
        except Exception as e:
            print(f"æº–å‚™ä»»å‹™å¤±æ•— {img_path}: {e}")


try:
    cv2.setNumThreads(1)
except Exception:
    pass
os.environ.setdefault("OMP_NUM_THREADS", "1")
os.environ.setdefault("OPENBLAS_NUM_THREADS", "1")
os.environ.setdefault("MKL_NUM_THREADS", "1")

jobs = list(_iter_jobs())
if not jobs:
    print("âš ï¸ æ²’æœ‰å¯è™•ç†çš„å½±åƒä»»å‹™ã€‚")
else:
    max_workers = min(8, (os.cpu_count() or 4))
    print(f"ğŸš€ ä¸¦è¡Œè™•ç† {len(jobs)} å¼µå½±åƒï¼Œworkers={max_workers}")
    with ThreadPoolExecutor(max_workers=max_workers) as ex:
        futures = [ex.submit(process_pair, img, pcd, outdir) for (img, pcd, outdir) in jobs]
        for fut in as_completed(futures):
            
            fut.result()